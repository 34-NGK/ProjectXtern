{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "try:\n",
    "    df = pd.read_csv('VeloCityX.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'VeloCityX.csv' was not found.\")\n",
    "    exit()\n",
    "\n",
    "# Display the first few rows to inspect the data\n",
    "print(\"Original Data:\\n\", df.head())\n",
    "\n",
    "# Check for missing values in all columns\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values (NaN)\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Remove duplicates across all columns\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "\n",
    "# Check for inconsistent data types for all columns\n",
    "print(\"\\nData Types Before Conversion:\")\n",
    "print(df_clean.dtypes)\n",
    "\n",
    "# Convert relevant columns to numeric, coercing errors to NaN\n",
    "numeric_columns = ['Fan Challenges Completed', 'Predictive Accuracy (%)', \n",
    "                   'Virtual Merchandise Purchases', 'Sponsorship Interactions (Ad Clicks)', \n",
    "                   'Time on Live 360 (mins)', 'Real-Time Chat Activity (Messages Sent)']\n",
    "\n",
    "for col in numeric_columns:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "# Re-check data types after conversion\n",
    "print(\"\\nData Types After Conversion:\")\n",
    "print(df_clean.dtypes)\n",
    "\n",
    "# Check for outliers in all numeric columns using the IQR method\n",
    "print(\"\\nSummary Statistics (Before Removing Outliers):\")\n",
    "print(df_clean.describe())\n",
    "\n",
    "for col in numeric_columns:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df_clean = df_clean[~((df_clean[col] < (Q1 - 1.5 * IQR)) | (df_clean[col] > (Q3 + 1.5 * IQR)))]\n",
    "\n",
    "# Summary statistics after outlier removal\n",
    "print(\"\\nSummary Statistics (After Removing Outliers):\")\n",
    "print(df_clean.describe())\n",
    "\n",
    "# Check if there are any duplicates left\n",
    "print(\"\\nDuplicate Rows Left (Should be 0):\")\n",
    "print(df_clean.duplicated().sum())\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df_clean.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "print(\"\\nData Cleaning Complete! The cleaned data has been saved as 'cleaned_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "data = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# Step 1: Calculate the average for each column (excluding 'User ID')\n",
    "column_means = data.drop(columns=['User ID']).mean()\n",
    "\n",
    "# Step 2: Get the top 10 users based on Virtual Merchandise Purchases (show only User ID and Purchase count)\n",
    "top_10_users = data[['User ID', 'Virtual Merchandise Purchases']].nlargest(10, 'Virtual Merchandise Purchases')\n",
    "print(\"Top 10 Users Based on Virtual Merchandise Purchases:\")\n",
    "print(top_10_users)\n",
    "\n",
    "# Step 3: Compare top 10 users' values to the averages and show where they exceeded the average\n",
    "columns_to_compare = ['Fan Challenges Completed', 'Predictive Accuracy (%)', 'Sponsorship Interactions (Ad Clicks)',\n",
    "                      'Time on Live 360 (mins)', 'Real-Time Chat Activity (Messages Sent)']\n",
    "\n",
    "# Compare each top 10 user to the averages, show if they are above or below for each column\n",
    "comparison_result = top_10_users[['User ID']].copy()\n",
    "for col in columns_to_compare:\n",
    "    comparison_result[col] = data.loc[top_10_users.index, col] > column_means[col]\n",
    "    comparison_result[col] = comparison_result[col].apply(lambda x: 'Above Average' if x else 'Below Average')\n",
    "\n",
    "# Step 4: Display results where users exceeded the average\n",
    "print(\"\\nTop 10 Users and Columns Where They Exceeded the Average:\")\n",
    "print(comparison_result)\n",
    "\n",
    "# Step 5: Count the number of top 10 users exceeding the average for each column\n",
    "exceed_counts = (data.loc[top_10_users.index, columns_to_compare] > column_means[columns_to_compare]).sum()\n",
    "\n",
    "# Step 6: Identify columns where more than 50% of the top 10 users exceeded the average\n",
    "high_impact_columns = exceed_counts[exceed_counts > len(top_10_users) / 2].index\n",
    "\n",
    "# Step 7: Print the columns where more than 50% of the top 10 users exceeded the average\n",
    "print(\"\\nColumns where More than 50% of Top 10 Users were Above Average:\")\n",
    "print(high_impact_columns)\n",
    "\n",
    "# Step 8: Perform a regression analysis to check how each column affects Virtual Merchandise Purchases\n",
    "# Define the independent variables (excluding 'User ID' and 'Virtual Merchandise Purchases') and the dependent variable\n",
    "X = data[columns_to_compare]\n",
    "y = data['Virtual Merchandise Purchases']\n",
    "\n",
    "# Add a constant to the independent variables (for the intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Perform the regression analysis\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the results of the regression analysis\n",
    "print(\"\\nOLS Regression Results:\")\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "print(\"I was hoping there would be a great coorelation between my average analysis and using the regression analysis to see which columns are most impactful. However, the results are not as expected.\")\n",
    "print(\"this means there is need for more  analysis to understand the relationship between the columns and the dependent variable.  I will need to perform more. \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# List of columns to check correlation with 'Virtual Merchandise Purchases'\n",
    "columns_to_check = ['Fan Challenges Completed', 'Predictive Accuracy (%)', \n",
    "                    'Sponsorship Interactions (Ad Clicks)', 'Time on Live 360 (mins)', \n",
    "                    'Real-Time Chat Activity (Messages Sent)']\n",
    "\n",
    "# Iterate over the columns and calculate correlation with 'Virtual Merchandise Purchases'\n",
    "for column in columns_to_check:\n",
    "    correlation = data[column].corr(data['Virtual Merchandise Purchases'])\n",
    "    print(f'Correlation between {column} and Virtual Merchandise Purchases: {correlation}')\n",
    "    \n",
    "    # Plot the figure\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(x=column, y='Virtual Merchandise Purchases', data=data)\n",
    "    plt.title(f'{column} vs Virtual Merchandise Purchases')\n",
    "\n",
    "    # Save the plot as a PNG file\n",
    "    file_name = f'{column.replace(\" \", \"_\").lower()}_vs_purchases.png'\n",
    "    plt.savefig(file_name)\n",
    "    print(f\"Plot saved as '{file_name}'\")\n",
    "\n",
    "\n",
    "print(\"Using Scatterplot I was able to conclude that Fan Challenges Completed and Sponsorship Interaction has the most direct correlation with Virtual Merchandise Purchases. This suggests that users who are more engaged those activities are more likely to make purchases. \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# Select relevant columns for clustering\n",
    "columns_to_use = ['Fan Challenges Completed', 'Predictive Accuracy (%)', \n",
    "                  'Sponsorship Interactions (Ad Clicks)', 'Time on Live 360 (mins)', \n",
    "                  'Real-Time Chat Activity (Messages Sent)', 'Virtual Merchandise Purchases']\n",
    "\n",
    "# Step 1: Data Preprocessing (Scaling the data)\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data[columns_to_use])\n",
    "\n",
    "# Step 2: Apply K-Means Clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)  # Trying 3 clusters (you can try more)\n",
    "data['Cluster'] = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "# Step 3: Visualize the Clusters for Each Column and Save as PNG files\n",
    "for column in columns_to_use[:-1]:  # Exclude 'Virtual Merchandise Purchases' for plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=column, y='Virtual Merchandise Purchases', hue='Cluster', data=data, palette='Set2')\n",
    "    plt.title(f'K-Means Clustering of Users Based on {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Virtual Merchandise Purchases')\n",
    "    \n",
    "    # Save the plot as a PNG file\n",
    "    file_name = f'{column.replace(\" \", \"_\").lower()}_vs_purchases K-Means.png'\n",
    "    plt.savefig(file_name)\n",
    "    plt.close()  # Close the figure to free up memory\n",
    "    print(f\"Plot saved as '{file_name}'\")\n",
    "    print('The combination of the clustering  results and the plots will help you understand the behavior of your users. Which lets us understand that the user who interacts with fan challenges completed and Sponsorship Interaction would be more likely to purchase merchandise. Which approves our hypothesis also.') \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
